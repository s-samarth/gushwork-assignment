# Additional Architectural Notes

## 1. Feature: Post-Capture Data Normalization
**Recommendation**: Data Normalization should be primarily done **post-capture** within the N8N workflow, rather than in the client-side JS snippet.
*   **Why?**
    1.  **Zero Data Loss Policy**: We treat the client script as a "dumb pipe." If we attempted strict filtering on the client side, we risk discarding valuable data simply because it didn't match a hardcoded list of field names (e.g., `custom_referral_source` or `urgent_deadline`).
    2.  **Contextual Intelligence**: Critical lead qualifiers are often buried in unstructured text or ambiguously named fields (e.g., a field named `details` could contain "I need 500 units by Friday"). Deterministic JS logic misses this; the N8N AI Smart Mapper captures it.
    3.  **The "Long Tail" of Field Names**: It is impossible to maintain a comprehensive list of every possible input name (`fname`, `user_name`, `contact_person`, `your_name_here`) inside a lightweight JS file. Server-side processing allows us to handle this infinite variance dynamically.
    4.  **Performance**: Keeping the script lightweight ensures fast load times and better UX.
*   **Solution**: We transmit "Raw Data" to N8N and use the **AI Smart Mapper** node to handle the chaos. This allows us to update normalization logic centrally on the server without redeploying the script to hundreds of client websites.

## 2. Technology Stack Comparison
Why did we choose **n8n** over Zapier or Make?

| Feature | üèÜ n8n | üî¥ Zapier | üü° Make (Integromat) |
| :--- | :--- | :--- | :--- |
| **Hosting** | **Self-hosted or Cloud** (High Privacy/GDPR) | Cloud Only | Cloud Only |
| **Cost Scale** | **Flat Rate** (Independent of volume) | **Per-Task Pricing** (Expensive at scale) | Operation-based (Moderate) |
| **Complex Logic** | **JavaScript Code Nodes** (Unlimited flexibility) | Limited (Python/JS requires upgrades) | Good Visual Logic |
| **Execution Limit** | **Virtually Unlimited** (Self-hosted) | Strict Tier Limits | Tier Limits |
| **Verdict** | **Preferred** for high-volume lead capture. | Rejected due to cost scaling. | Strong alternative, but less flexible. |

## 2. Standardized Payload Schema
The `lead-capture.js` script enforces a strict separation between user data and system metadata to prevent collisions.

| Key | Description | Source |
| :--- | :--- | :--- |
| **`data`** | The raw form fields (key-value pairs) | `FormData` extraction |
| **`meta.clientId`** | Unique identifier for the Gushwork client | Script Configuration (`CONFIG`) |
| **`meta.sourceUrl`** | The URL where the form was submitted | `window.location.href` |
| **`meta.referrer`** | The page the user came from (attribution) | `document.referrer` |
| **`meta.userAgent`** | Browser string (used for spam detection) | `navigator.userAgent` |
| **`meta.timestamp`** | ISO 8601 timestamp of submission | `new Date().toISOString()` |

## 3. Advanced Security & Reliability

### CSP Nonce implementation (Strict Security)
For enterprise clients with **Strict Content Security Policy (CSP)**, simply whitelisting domains might not be enough.
*   **Recommendation**: The script tag itself should include a cryptographic **nonce** generated by the server.
*   **Implementation**: `<script src="..." nonce="random_value_generated_by_server">`
*   **Note**: This requires coordination with the client's DevOps team to dynamically generate nonces on their backend.

### Idempotency Strategy (Preventing Duplicates)
To ensure no lead is processed twice (e.g., if a webhook retries on failure), we recommend generating a unique hash for every submission.
*   **Logic**: `Hash(email + timestamp + sourceUrl)`
*   **Workflow**:
    1.  Generate Hash in N8N.
    2.  Check Database: "Does this hash exist?"
    3.  If **Yes**: Stop execution (Duplicate).
    4.  If **No**: Proceed and save hash.
